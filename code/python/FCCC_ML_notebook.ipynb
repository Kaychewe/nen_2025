{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415e94a8-daf3-41f6-b6e8-f0df19161fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Manuscript data\n",
    "# 1. expr -> expression matrix (36, 785)\n",
    "# 2. meta -> metadata \n",
    "expr = pd.read_csv(\"ml_input/expression_log2_counts.tsv\", sep=\"\\t\")\n",
    "meta = pd.read_csv(\"ml_input/sample_metadata.tsv\", sep=\"\\t\")\n",
    "\n",
    "expr = expr.sort_values(\"sample_id\").reset_index(drop=True)\n",
    "meta = meta.sort_values(\"sample_id\").reset_index(drop=True)\n",
    "\n",
    "assert all(expr[\"sample_id\"] == meta[\"sample_id\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8006c381-bbc1-4439-8346-d5acdcc3ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Features \n",
    "X = expr.drop(columns=[\"sample_id\"]).values\n",
    "gene_names = expr.drop(columns=['sample_id']).columns.to_list()\n",
    "\n",
    "# Labels: PD = 1 (positive), WD = 0 (negative)\n",
    "y = (meta[\"nen_subtype\"] == \"PD\").astype(int).values\n",
    "# print(y)\n",
    "# print(meta[\"nen_subtype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "849186b5-3471-4a36-b57f-e8c5301bb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=23\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cefda05-1973-408e-9b7f-70b0b4e41dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"liblinear\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=23\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=23\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "738f55c9-a7b0-46a5-abe9-efa921fc1b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR train AUC: 1.0\n",
      "LR test  AUC: 0.9666666666666667\n",
      "RF train AUC: 1.0\n",
      "RF test  AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"LR train AUC:\", roc_auc_score(y_train, lr.predict_proba(X_train)[:, 1]))\n",
    "print(\"LR test  AUC:\", roc_auc_score(y_test,  lr.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "print(\"RF train AUC:\", roc_auc_score(y_train, rf.predict_proba(X_train)[:, 1]))\n",
    "print(\"RF test  AUC:\", roc_auc_score(y_test,  rf.predict_proba(X_test)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b8fa639-7027-4e28-b171-91029f366fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0\n",
      "7 1.0\n",
      "13 1.0\n",
      "23 1.0\n",
      "42 1.0\n",
      "101 1.0\n"
     ]
    }
   ],
   "source": [
    "for seed in [1, 7, 13, 23, 42, 101]:\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=seed\n",
    "    )\n",
    "    lr.fit(X_tr, y_tr)\n",
    "    auc = roc_auc_score(y_te, lr.predict_proba(X_te)[:,1])\n",
    "    print(seed, auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1fa28fe-674f-4d55-9c2d-5743eafb5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "penalty=l2 | solver=liblinear | class_weight=balanced\n",
      "Encoding: PD = 1, WD = 0\n",
      "Stratify: False\n",
      "-------------------------------------\n",
      "\n",
      "=== Top 10 most variable genes ===\n",
      "  Split 75/25 | N=149 | min=0.786 | mean=0.986 | max=1.000\n",
      "  Split 70/30 | N=150 | min=0.875 | mean=0.987 | max=1.000\n",
      "\n",
      "=== Top 25 most variable genes ===\n",
      "  Split 75/25 | N=149 | min=0.889 | mean=0.992 | max=1.000\n",
      "  Split 70/30 | N=150 | min=0.833 | mean=0.991 | max=1.000\n",
      "\n",
      "=== Top 30 most variable genes ===\n",
      "  Split 75/25 | N=149 | min=0.889 | mean=0.990 | max=1.000\n",
      "  Split 70/30 | N=150 | min=0.833 | mean=0.989 | max=1.000\n",
      "\n",
      "=== Top 50 most variable genes ===\n",
      "  Split 75/25 | N=149 | min=0.900 | mean=0.996 | max=1.000\n",
      "  Split 70/30 | N=150 | min=0.867 | mean=0.995 | max=1.000\n",
      "\n",
      "=== Top 100 most variable genes ===\n",
      "  Split 75/25 | N=149 | min=0.950 | mean=1.000 | max=1.000\n",
      "  Split 70/30 | N=150 | min=0.900 | mean=0.999 | max=1.000\n",
      "\n",
      "=== Top 200 most variable genes ===\n",
      "  Split 75/25 | N=149 | min=1.000 | mean=1.000 | max=1.000\n",
      "  Split 70/30 | N=150 | min=0.967 | mean=1.000 | max=1.000\n",
      "\n",
      "=== Top 300 most variable genes ===\n",
      "  Split 75/25 | N=149 | min=1.000 | mean=1.000 | max=1.000\n",
      "  Split 70/30 | N=150 | min=0.967 | mean=1.000 | max=1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ----------------------------\n",
    "# Fixed data + labels\n",
    "# ----------------------------\n",
    "X_full = expr.drop(columns=[\"sample_id\"]).values\n",
    "y = (meta[\"nen_subtype\"] == \"PD\").astype(int).values\n",
    "gene_names = expr.drop(columns=[\"sample_id\"]).columns.to_list()\n",
    "\n",
    "# ----------------------------\n",
    "# Gene-wise variance\n",
    "# ----------------------------\n",
    "gene_var = np.var(X_full, axis=0)\n",
    "var_rank_idx = np.argsort(gene_var)[::-1]  # descending variance\n",
    "\n",
    "# ----------------------------\n",
    "# Logistic Regression config\n",
    "# ----------------------------\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"liblinear\",\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"penalty=l2 | solver=liblinear | class_weight=balanced\")\n",
    "print(\"Encoding: PD = 1, WD = 0\")\n",
    "print(\"Stratify: False\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "# ----------------------------\n",
    "# Variance filter sweep\n",
    "# ----------------------------\n",
    "for n_genes in [10, 25, 30, 50, 100, 200, 300]:\n",
    "    print(f\"\\n=== Top {n_genes} most variable genes ===\")\n",
    "\n",
    "    X = X_full[:, var_rank_idx[:n_genes]]\n",
    "\n",
    "    for test_size in [0.25, 0.30]:\n",
    "        aucs = []\n",
    "\n",
    "        for seed in range(1, 151):\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "                X,\n",
    "                y,\n",
    "                test_size=test_size,\n",
    "                random_state=seed\n",
    "            )\n",
    "\n",
    "            # Skip degenerate test splits\n",
    "            if len(np.unique(y_te)) < 2:\n",
    "                continue\n",
    "\n",
    "            lr.fit(X_tr, y_tr)\n",
    "            y_score = lr.predict_proba(X_te)[:, 1]\n",
    "            aucs.append(roc_auc_score(y_te, y_score))\n",
    "\n",
    "        if len(aucs) == 0:\n",
    "            print(f\"  Split {int((1-test_size)*100)}/{int(test_size*100)}: no valid splits\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"  Split {int((1-test_size)*100)}/{int(test_size*100)} | \"\n",
    "                f\"N={len(aucs):3d} | \"\n",
    "                f\"min={np.min(aucs):.3f} | \"\n",
    "                f\"mean={np.mean(aucs):.3f} | \"\n",
    "                f\"max={np.max(aucs):.3f}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ed7288d-f446-41c7-bccc-aed39aff6901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Supervised feature selection: Welch t-test (PD vs WD) ===\n",
      "Labels: PD=1, WD=0 | Stratify: False\n",
      "LR: penalty=l2 | solver=liblinear | class_weight=balanced | max_iter=1000\n",
      "RF: n_estimators=1000 | max_features=sqrt | class_weight=balanced | random_state=seed\n",
      "------------------------------------------------------------\n",
      "\n",
      "### MODE 1: LEAKY / Global DE ranking (computed once on ALL samples) ###\n",
      "TopN= 10 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=1.000/1.000/1.000\n",
      "TopN= 10 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=1.000/1.000/1.000\n",
      "TopN= 25 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.998/1.000\n",
      "TopN= 25 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.999/1.000\n",
      "TopN= 50 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.997/1.000\n",
      "TopN= 50 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.998/1.000\n",
      "TopN= 75 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.997/1.000\n",
      "TopN= 75 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.998/1.000\n",
      "TopN=100 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.997/1.000\n",
      "TopN=100 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.998/1.000\n",
      "TopN=150 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.997/1.000\n",
      "TopN=150 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.997/1.000\n",
      "TopN=200 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.996/1.000\n",
      "TopN=200 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.998/1.000\n",
      "\n",
      "\n",
      "### MODE 2: TRAIN-ONLY DE ranking (recomputed inside each split) ###\n",
      "TopN= 10 | split 75/25 | N=149 | LR min/mean/max=0.950/1.000/1.000 | RF min/mean/max=0.833/0.996/1.000\n",
      "TopN= 10 | split 70/30 | N=150 | LR min/mean/max=0.821/0.997/1.000 | RF min/mean/max=0.857/0.996/1.000\n",
      "TopN= 25 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.997/1.000\n",
      "TopN= 25 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.998/1.000\n",
      "TopN= 50 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.996/1.000\n",
      "TopN= 50 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.997/1.000\n",
      "TopN= 75 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.996/1.000\n",
      "TopN= 75 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.929/0.996/1.000\n",
      "TopN=100 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.996/1.000\n",
      "TopN=100 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.996/1.000\n",
      "TopN=150 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.833/0.995/1.000\n",
      "TopN=150 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.875/0.996/1.000\n",
      "TopN=200 | split 75/25 | N=149 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.833/0.994/1.000\n",
      "TopN=200 | split 70/30 | N=150 | LR min/mean/max=1.000/1.000/1.000 | RF min/mean/max=0.867/0.996/1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ----------------------------\n",
    "# Data\n",
    "# ----------------------------\n",
    "X_full = expr.drop(columns=[\"sample_id\"]).values\n",
    "gene_names = expr.drop(columns=[\"sample_id\"]).columns.to_list()\n",
    "y = (meta[\"nen_subtype\"] == \"PD\").astype(int).values  # PD=1, WD=0\n",
    "\n",
    "# ----------------------------\n",
    "# Model configs (match your earlier setup style)\n",
    "# ----------------------------\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"liblinear\",\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "def make_rf(seed: int):\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=1000,\n",
    "        max_features=\"sqrt\",\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "print(\"=== Supervised feature selection: Welch t-test (PD vs WD) ===\")\n",
    "print(\"Labels: PD=1, WD=0 | Stratify: False\")\n",
    "print(\"LR: penalty=l2 | solver=liblinear | class_weight=balanced | max_iter=1000\")\n",
    "print(\"RF: n_estimators=1000 | max_features=sqrt | class_weight=balanced | random_state=seed\")\n",
    "print(\"------------------------------------------------------------\\n\")\n",
    "\n",
    "# ----------------------------\n",
    "# Welch t-test ranking (no scipy dependency)\n",
    "# Returns indices sorted by ascending p-value (most significant first)\n",
    "# ----------------------------\n",
    "def welch_t_rank(X: np.ndarray, y_bin: np.ndarray) -> np.ndarray:\n",
    "    X1 = X[y_bin == 1]\n",
    "    X0 = X[y_bin == 0]\n",
    "\n",
    "    n1 = X1.shape[0]\n",
    "    n0 = X0.shape[0]\n",
    "\n",
    "    m1 = X1.mean(axis=0)\n",
    "    m0 = X0.mean(axis=0)\n",
    "\n",
    "    v1 = X1.var(axis=0, ddof=1)\n",
    "    v0 = X0.var(axis=0, ddof=1)\n",
    "\n",
    "    # Welch t-statistic\n",
    "    denom = np.sqrt((v1 / n1) + (v0 / n0))\n",
    "    denom = np.where(denom == 0, np.nan, denom)\n",
    "    t = (m1 - m0) / denom\n",
    "\n",
    "    # Approximate ranking by |t| if p-values can't be computed reliably without scipy\n",
    "    # (still a supervised ranking; many older notebooks effectively did this)\n",
    "    # Use nan_to_num so constant genes don't break sorting\n",
    "    score = np.nan_to_num(np.abs(t), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Sort descending by |t|\n",
    "    return np.argsort(score)[::-1]\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation helper\n",
    "# ----------------------------\n",
    "def eval_once(X_tr, X_te, y_tr, y_te, seed: int):\n",
    "    # LR\n",
    "    lr.fit(X_tr, y_tr)\n",
    "    lr_auc = roc_auc_score(y_te, lr.predict_proba(X_te)[:, 1])\n",
    "\n",
    "    # RF\n",
    "    rf = make_rf(seed)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    rf_auc = roc_auc_score(y_te, rf.predict_proba(X_te)[:, 1])\n",
    "\n",
    "    return lr_auc, rf_auc\n",
    "\n",
    "topNs = [10, 25, 50, 75, 100, 150, 200]\n",
    "splits = [0.25, 0.30]\n",
    "seeds = range(1, 151)\n",
    "\n",
    "# ============================================================\n",
    "# MODE 1: \"LEAKY / Global DE\" (most likely historical)\n",
    "# ============================================================\n",
    "global_rank_idx = welch_t_rank(X_full, y)\n",
    "\n",
    "print(\"### MODE 1: LEAKY / Global DE ranking (computed once on ALL samples) ###\")\n",
    "for n_genes in topNs:\n",
    "    feat_idx = global_rank_idx[:n_genes]\n",
    "    X = X_full[:, feat_idx]\n",
    "\n",
    "    for test_size in splits:\n",
    "        lr_aucs, rf_aucs = [], []\n",
    "\n",
    "        for seed in seeds:\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=seed\n",
    "            )\n",
    "            if len(np.unique(y_te)) < 2:\n",
    "                continue\n",
    "\n",
    "            lr_auc, rf_auc = eval_once(X_tr, X_te, y_tr, y_te, seed)\n",
    "            lr_aucs.append(lr_auc)\n",
    "            rf_aucs.append(rf_auc)\n",
    "\n",
    "        if len(lr_aucs) == 0:\n",
    "            print(f\"TopN={n_genes:3d} | split {int((1-test_size)*100)}/{int(test_size*100)}: no valid splits\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"TopN={n_genes:3d} | split {int((1-test_size)*100)}/{int(test_size*100)} | \"\n",
    "                f\"N={len(lr_aucs):3d} | \"\n",
    "                f\"LR min/mean/max={np.min(lr_aucs):.3f}/{np.mean(lr_aucs):.3f}/{np.max(lr_aucs):.3f} | \"\n",
    "                f\"RF min/mean/max={np.min(rf_aucs):.3f}/{np.mean(rf_aucs):.3f}/{np.max(rf_aucs):.3f}\"\n",
    "            )\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# MODE 2: TRAIN-ONLY DE (modern correct; included for comparison)\n",
    "# ============================================================\n",
    "print(\"### MODE 2: TRAIN-ONLY DE ranking (recomputed inside each split) ###\")\n",
    "for n_genes in topNs:\n",
    "    for test_size in splits:\n",
    "        lr_aucs, rf_aucs = [], []\n",
    "\n",
    "        for seed in seeds:\n",
    "            X_tr_full, X_te_full, y_tr, y_te = train_test_split(\n",
    "                X_full, y, test_size=test_size, random_state=seed\n",
    "            )\n",
    "            if len(np.unique(y_te)) < 2:\n",
    "                continue\n",
    "\n",
    "            # DE ranking using TRAIN ONLY\n",
    "            rank_idx = welch_t_rank(X_tr_full, y_tr)\n",
    "            feat_idx = rank_idx[:n_genes]\n",
    "\n",
    "            X_tr = X_tr_full[:, feat_idx]\n",
    "            X_te = X_te_full[:, feat_idx]\n",
    "\n",
    "            lr_auc, rf_auc = eval_once(X_tr, X_te, y_tr, y_te, seed)\n",
    "            lr_aucs.append(lr_auc)\n",
    "            rf_aucs.append(rf_auc)\n",
    "\n",
    "        if len(lr_aucs) == 0:\n",
    "            print(f\"TopN={n_genes:3d} | split {int((1-test_size)*100)}/{int(test_size*100)}: no valid splits\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"TopN={n_genes:3d} | split {int((1-test_size)*100)}/{int(test_size*100)} | \"\n",
    "                f\"N={len(lr_aucs):3d} | \"\n",
    "                f\"LR min/mean/max={np.min(lr_aucs):.3f}/{np.mean(lr_aucs):.3f}/{np.max(lr_aucs):.3f} | \"\n",
    "                f\"RF min/mean/max={np.min(rf_aucs):.3f}/{np.mean(rf_aucs):.3f}/{np.max(rf_aucs):.3f}\"\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
